# MMU

The work of the MMU can be divided into three major categories:

- Hardware memory management, which oversees and regulates the processor's use of [RAM](https://searchstorage.techtarget.com/definition/RAM-random-access-memory) (random access memory) and cache memory.
- [OS](https://whatis.techtarget.com/definition/operating-system-OS) (operating system) memory management, which ensures the availability of adequate memory resources for the [objects](https://searchmicroservices.techtarget.com/definition/object) and [data structures](https://searchsqlserver.techtarget.com/definition/data-structure) of each running [program](https://searchsoftwarequality.techtarget.com/definition/program) at all times.
- [Application](https://searchsoftwarequality.techtarget.com/definition/application-program) memory management, which allocates each individual program's required memory, and then recycles freed-up memory space when the operation concludes.

MMU将VA映射到PA是以页（Page）为单位的，32位处理器的页尺寸通常是4KB。例如，MMU可以通过一个映射项将VA的一页0xb7001000~0xb7001fff映射到PA的一页0x2000~0x2fff，如果CPU执行单元要访问虚拟地址0xb7001008，则实际访问到的物理地址是0x2008。物理内存中的页称为物理页面或者页帧（Page Frame）。虚拟内存的哪个页面映射到物理内存的哪个页帧是通过页表（Page Table）来描述的，页表保存在物理内存中，MMU会查找页表来确定一个VA应该映射到什么PA。

操作系统和MMU是这样配合的：

1. 操作系统在初始化或分配、释放内存时会执行一些指令在物理内存中填写页表，然后用指令设置MMU，告诉MMU页表在物理内存中的什么位置。
2. 设置好之后，CPU每次执行访问内存的指令都会自动引发MMU做查表和地址转换操作，地址转换操作由硬件自动完成，不需要用指令控制MMU去做。

我们在程序中使用的变量和函数都有各自的地址，程序被编译后，这些地址就成了指令中的地址，指令中的地址被CPU解释执行，就成了CPU执行单元发出的内存地址，所以在启用MMU的情况下，程序中使用的地址都是虚拟地址，都会引发MMU做查表和地址转换操作。那为什么要设计这么复杂的内存管理机制呢？多了一层VA到PA的转换到底换来了什么好处？All problems in computer science can be solved by another level of indirection.还记得这句话吗？多了一层间接必然是为了解决什么问题的，等讲完了必要的预备知识之后，将在MMU（二）讨论虚拟内存管理机制的作用。

MMU除了做**地址转换**之外，还提供**内存保护机制**。各种体系结构都有用户模式（User Mode）和特权模式（Privileged Mode）之分，操作系统可以在页表中设置每个内存页面的访问权限，有些页面不允许访问，有些页面只有在CPU处于特权模式时才允许访问，有些页面在用户模式和特权模式都可以访问，访问权限又分为可读、可写和可执行三种。这样设定好之后，当CPU要访问一个VA时，MMU会检查CPU当前处于用户模式还是特权模式，访问内存的目的是读数据、写数据还是取指令，如果和操作系统设定的页面权限相符，就允许访问，把它转换成PA，否则不允许访问，产生一个异常（Exception）。异常的处理过程和中断类似，不同的是中断由外部设备产生而异常由CPU内部产生，中断产生的原因和CPU当前执行的指令无关，而异常的产生就是由于CPU当前执行的指令出了问题，例如访问内存的指令被MMU检查出权限错误，除法指令的除数为0等都会产生异常。

通常操作系统把虚拟地址空间划分为用户空间和内核空间，例如x86平台的Linux系统虚拟地址空间是0x00000000~0xffffffff，前3GB（0x00000000~0xbfffffff）是用户空间，后1GB（0xc0000000~0xffffffff）是内核空间。用户程序加载到用户空间，在用户模式下执行，不能访问内核中的数据，也不能跳转到内核代码中执行。这样可以保护内核，如果一个进程访问了非法地址，顶多这一个进程崩溃，而不会影响到内核和整个系统的稳定性。CPU在产生中断或异常时不仅会跳转到中断或异常服务程序，还会自动切换模式，从用户模式切换到特权模式，因此从中断或异常服务程序可以跳转到内核代码中执行。事实上，整个内核就是由各种中断和异常处理程序组成的。总结一下：在正常情况下处理器在用户模式执行用户程序，在中断或异常情况下处理器切换到特权模式执行内核程序，处理完中断或异常之后再返回用户模式继续执行用户程序。

段错误我们已经遇到过很多次了，它是这样产生的：

1. 用户程序要访问的一个VA，经MMU检查无权访问。
2. MMU产生一个异常，CPU从用户模式切换到特权模式，跳转到内核代码中执行异常服务程序。
3. 内核把这个异常解释为段错误，把引发异常的进程终止掉。





简单地说， MMU 的作用有两点：地址翻译、内存保护。

1 、地址翻译

​      在处理器上一般会运行一个操作系统，如 Linux ，用户编写的源程序需要经过编译、链接得到可执行文件，然后被操作系统加载执行。编译、链接的过程在第 2 章实验环境搭建中有过描述，在链接的时候需要指定一个链接描述脚本，链接描述脚本有很多作用，其中一项是控制可执行文件中 Section 和符号的内存布局，也就是控制可执行程序在内存中是如何放置的，操作系统会按照可执行文件的要求将其加载到内存对应地址并执行。假如用户 A 编写了程序 ProgramA ，并且 ProgramA 占用的内存空间是 0x100-0x200 ，用户 B 编写了程序 ProgramB ，并且 ProgramB 要求的内存空间也是 0x100-0x200 ，这是完全有可能的，因为给操作系统提供程序的用户很多，不可能限定每个用户使用不同部分的内存。这样当 ProgramA 被加载执行时， ProgramB 就不能被加载执行，一旦 ProgramB 也被加载了就会破坏 ProgramA 的执行，因为后者会覆盖 ProgramA 占用的内存。为了解决这个问题，将操作系统和处理器都做了修改，添加了 MMU ，在其中进行地址翻译，程序加载入内存的时候为其建立地址翻译表，处理器执行不同程序的时候使用不同的地址翻译表，如图 10.1 所示。

![img](https://img1.tuicool.com/vuEr63.jpg!web)

​      ProgramA 被加载到地址 0x500-0x600 处， ProgramB 被加载到地址 0x700-0x800 处，同时建立了各自的地址翻译表，当处理器要执行 ProgramB 时，会使用 ProgramB 对应的地址翻译表，比如读取 ProgramB 地址 0x100 处的指令，那么经过地址翻译表可知 0x100 对应实际内存的0x700 处，所以实际读取的就是 0x700 处的指令。同样的，当处理器要执行 ProgramA 时，会使用 ProgramA 对应的地址翻译表，这样就避免了之前提到的内存冲突问题，有了 MMU 的支持，操作系统就可以轻松实现多任务了。

​      图 10.1 中 CPU 给出的地址称之为虚拟地址（ OR1200 中称之为有效地址 EA ），经过 MMU 翻译后的地址称之为物理地址。

​      MMU 的地址翻译功能还可以为用户提供比实际大得多的内存空间。用户在编写程序的时候并不知道运行该程序的计算机内存大小，如果在链接的时候指定程序被加载到地址 Addr 处，而运行该程序的计算机内存小于 Addr ，那么程序就无法执行，有了 MMU 后，程序员就不用关心实际内存大小，可以认为内存大小就是“ 2^ 指令地址宽度”。 MMU 会将超过实际内存的虚拟地址翻译为物理地址进行访问。

​      地址翻译表存储在内存中，如果采用图 10.1 中的方式：地址翻译表的表项是一个虚拟地址对应一个物理地址，那么会占用太多的内存空间，为此，需要修改翻译方式，常用的有三种：页式、段式、段页式，这也是三种不同的内存管理方式。

​      页式内存管理将虚拟内存、物理内存空间划分为大小固定的块，每一块称之为一页，以页为单位来分配、管理、保护内存。此时 MMU 中的地址翻译表称为页表（ Page Table ），每个任务或进程对应一个页表，页表由若干个页表项（ PTE ： Page Table Entry ）组成，每个页表项对应一个虚页，内含有关地址翻译的信息和一些控制信息。在页式内存管理方式中地址由页号和页内位移两部分组成，其地址翻译方式如图 10.2 所示。

![img](https://img1.tuicool.com/RNRjeq.jpg!web)

​      使用虚拟地址中的虚页号查询页表得到对应的物理页号，然后与虚拟地址中的页内位移组成物理地址。比如：页大小是 256 字节，虚拟地址是 0x104 ，可知对应的虚页号是 0x1 ，页内位移是 0x4 ，假如通过页表翻译得到的对应物理页号是 0x7 ，那么 0x104 对应的物理地址就是 0x704。使用页表方式进行地址翻译可以有效减少地址翻译表占用的内存空间，还是以图 10.1 为例，页大小是 256 字节，此时每个程序对应的页表就只有两项，如图 10.3 所示。

![img](https://img0.tuicool.com/iUJFZf.jpg!web)

​      段式内存管理将虚拟内存、物理内存空间划分为段进行管理，段的大小取决于程序的逻辑结构，可长可短，一般将一个具有共同属性的程序代码和数据定义在一个段中。每个任务和进程对应一个段表（ Segment Table ），段表由若干个段表项（ STE ： Segment Table Entry ）组成，内含地址映像信息（段基址和段长度）等内容。在段式虚拟存储器中，地址分为段号、段内位移两部分，使用段表进行地址翻译的过程与使用页表进行地址翻译的过程是相似的。

​      段页式内存管理是在内存分段的基础上再分页，即每段分成若干个固定大小的页。每个任务或进程对应有一个段表，每段对应有自己的页表。在访问存储器时，由 CPU 经页表对段内存储单元进行寻址。

​      OR1200 处理器中的 MMU 使用页表进行地址翻译，所以本章对段式、段页式不做过多着墨，同时，下文介绍内存保护、 TLB 时都默认是页式内存管理。

​      2 、内存保护

​       MMU 除了具有地址翻译的功能外，还提供了内存保护功能。采用页式内存管理时可以提供页粒度级别的保护，允许对单一内存页设置某一类用户的读、写、执行权限，比如：一个页中存储代码，并且该代码不允许在用户模式下执行，那么可以设置该页的保护属性，这样当处理器在用户模式下要求执行该页的代码时， MMU 会检测到并触发异常，从而实现对代码的保护。下文在分析 OR1200 处理器中 MMU 模块时会具体介绍内存保护的实现机制。



  MMU即内存管理单元(Memory Manage Unit），是一个与软件密切相关的硬件部件，也是理解Linux等操作系统内核机制的最大障碍之一。可以说，不懂MMU使很多人一直停滞在单片机与无OS的时代。那么，今天我们就来说说MMU，其中有几个概念是阻碍人们理解MMU的元凶。
1）虚拟地址/物理地址
如果处理器没有MMU，CPU内部执行单元产生的内存地址信号将直接通过地址总线发送到芯片引脚，被内存芯片接收，这就是物理地址(physical address)，简称PA。英文physical代表物理的接触，所以PA就是与内存芯片physically connected的总线上的信号。
如果MMU存在且启用，CPU执行单元产生的地址信号在发送到内存芯片之前将被MMU截获，这个地址信号称为虚拟地址（virtual address），简称VA，MMU会负责把VA翻译成另一个地址，然后发到内存芯片地址引脚上，即VA映射成PA
软件上MMU对用户程序不可见，在启用MMU的平台上（没有MMU不必说，只有物理地址，不存在虚拟地址），用户C程序中变量和函数背后的数据/指令地址等都是虚拟地址，这些虚拟内存地址从CPU执行单元⑤发出后，都会首先被MMU拦截并转换成物理地址，然后再发送给内存。也就是说用户程序运行*pA =100;"这条赋值语句时，假设debugger显示指针pA的值为0x30004000（虚拟地址），但此时通过硬件工具（如逻辑分析仪）侦测到的CPU与外存芯片间总线信号很可能是另外一个值,如0x8000（物理地址）。
当然对一般程序员来说，只要上述语句运行后debugger显示0x30004000位置处的内存值为100就行了，根本无需关心pA的物理地址是多少。但进行OS移植或驱动开发的系统程序员不同，他们必须清楚软件如何在幕后辅助硬件MMU完成地址转换。
暂不探讨这种复杂机制的历史原因，很多人学习或阐述MMU时，都迷失于对一些相关发散问题的无休止探究，我们暂时抽身出来，用一句话做阶段性交待，"所有计算机科学中的问题都能通过增加一个中间转换层来解决"（"All problems in computer science can be solved by another level of indirection"）。某种程度上，这种被动解决问题的方式使计算机软硬件的一系列发展只不过是惯性向前，看起来顺理成章，然而几乎所有从业者的智慧都浪费在不断学习和构建新的中间层，身不由己的推动这个庞然大物继续膨胀。忽然感觉索然无味，很无聊啊。
2 ) 页/页帧/页表/页表项(PTE)
这几个页概念也噎倒了不少人，这里澄清下。MMU是负责把虚拟地址映射为物理地址，但凡"映射"都要解决两个问题：映射的最小单位（粒度）和映射的规则。

MMU中VA到PA映射的最小单位称为页(Page)，映射的最低粒度是单个虚拟页到物理页，页大小通常是4K，即一次最少要把4K大小的VA页块整体映射到4K的PA页块（从0开始4K对齐划分页块），页内偏移不变，如VA的一页0x30004000~0x30004fff被映射到PA的一页 0x00008000~0x00008fff，当CPU执行单元访问虚拟地址0x30004008，实际访问的物理地址是0x00008008（0x30004008和0x00008008分别位于虚实两套地址空间，互不相干，不存在重叠和冲突）。以页为最小单位，就是不能把VA中某一页划分成几小块分别映射到不同PA，也不能把VA中属于不同页的碎块映射到PA某一页的不同部分，必须页对页整体映射。

页帧（Page Frame）是指物理内存中的一页内存，MMU虚实地址映射就是寻找物理页帧的过程，对这个概念了解就可以了。

MMU软件配置的核心是页表（Page Table），它描述MMU的映射规则，即虚拟内存哪(几)个页映射到物理内存哪(几)个页帧。页表由一条条代表映射规则的记录组成，每一条称为一个页表条目（Page Table Entry,即PTE），整个页表保存在片外内存，MMU通过查找页表确定一个VA应该映射到什么PA，以及是否有权限映射。

但如果MMU每次地址转换都到位于外部内存的页表上查找PTE，转换速度就会大大降低，于是出现了
3) TLB
TLB (Translation Lookaside Buffers)即转换快表，又简称快表，可以理解为MMU内部专用的存放页表的cache，保存着最近使用的PTE乃至全部页表。MMU接收到虚拟地址后，首先在TLB中查找，如果找到该VA对应的PTE就直接转换，找不到再去外存页表查找，并置换进TLB。TLB属于片上SRAM，访问速度快，通过TLB缓存PTE可以节省MMU访问外存页表的时间，从而加速虚实地址转换。TLB和CPU cache的工作原理一样，只是TLB专用于为MMU缓存页表。
4) MMU的内存保护功能
既然所有发往内存的地址信号都要经过MMU处理，那让它只单单做地址转换，岂不是浪费了这个特意安插的转换层?显然它有能力对虚地址访问做更多的限定(就像路由器转发网络包的同时还能过滤各种非法访问)，比如内存保护。可以在PTE条目中预留出几个比特，用于设置访问权限的属性，如禁止访问、可读、可写和可执行等。设好后，CPU访问一个VA时，MMU找到页表中对应PTE，把指令的权限需求与该PTE中的限定条件做比对，若符合要求就把VA转换成PA，否则不允许访问，并产生异常。
5) 多级页表
虚拟地址由页号和页内偏移组成。什么东东呢?

前面说过MMU映射以页为最小单位，假设页大小为4K(212)，那么无论页表怎样设置，虚拟地址后12比特与MMU映射后的物理地址后12比特总是相同，这不变的比特位就是页内偏移。为什么不变？拜托，把搭积木想象成一种映射，不管你怎么搭，你也改变不了每块积木内部的原子排列吧。所谓以页为最小单位就是保持一部分不变作为最小粒度。

页号就更有故事了，一个32bits虚拟地址，可以划分为220个内存页，如果都以页为单位和物理页帧随意映射，页表的空间占用就是220*sizeof(PTE)*进程数（每个进程都要有自己的页表），PTE一般占4字节，即每进程4M，这对空间占用和MMU查询速度都很不利。更多学习资料可以加宋老师企鹅号三5二四六五9088

问题是实际应用中不需要每次都按最小粒度的页来映射，很多时候可以映射更大的内存块。因此最好采用变化的映射粒度，既灵活又可以减小页表空间。具体说可以把20bits的页号再划分为几部分
简单说每次MMU根据虚拟地址查询页表都是一级级进行，先根据PGD的值查询，如果查到PGD的匹配，但后续PMD和PTE没有，就以2(offset+pte+pmd)=1M为粒度进行映射，后20bits全部是块内偏移，与物理地址相同。

依次类推，具体可参考WolfGang Mauerer的professional linux kernel architecture的1.3.4节，以及各CPU的Spec中MMU章节，查看MMU组合出物理地址的详细过程。
6) 操作系统和MMU
实际上MMU是为满足操作系统越来越复杂的内存管理而产生的。OS和MMU的关系简单说：

a.系统初始化代码会在内存中生成页表，然后把页表地址设置给MMU对应寄存器，使MMU知道页表在物理内存中的什么位置，以便在需要时进行查找。之后通过专用指令启动MMU，以此为分界，之后程序中所有内存地址都变成虚地址，MMU硬件开始自动完成查表和虚实地址转换。

b.OS初始化后期，创建第一个用户进程，这个过程中也需要创建页表，把其地址赋给进程结构体中某指针成员变量。即每个进程都要有独立的页表。

c.用户创建新进程时，子进程拷贝一份父进程的页表，之后随着程序运行，页表内容逐渐更新变化。比较复杂了，几句讲不清楚，不多说了哈，有时间讲linux的话再说吧
6) 总结
相关概念讲完，VA到PA的映射过程就一目了然：MMU得到VA后先在TLB内查找，若没找到匹配的PTE条目就到外部页表查询，并置换进TLB；根据PTE条目中对访问权限的限定检查该条VA指令是否符合，若不符合则不继续，并抛出exception异常；符合后根据VA的地址分段查询页表，保持offset(广义)不变，组合出物理地址，发送出去。

在这个过程中,软件的工作核心就是生成和配置页表。  